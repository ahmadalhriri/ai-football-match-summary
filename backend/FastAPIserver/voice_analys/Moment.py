import json
import re
from tqdm import tqdm
from sentence_transformers import SentenceTransformer, util

class MomentClassifier:
    def __init__(self, window_size=2, threshold=0.95):
        print("ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ...")
        self.model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
        self.window_size = window_size
        self.threshold = threshold
        self.reference_phrases = {
        "goal": ["Ù‡Ø¯Ù", "ØºÙˆÙˆÙˆÙ„", "Ø³Ø¬Ù„Ù‡Ø§", "Ø§Ù„Ø´Ø¨Ø§Ùƒ", "Ø§Ù„Ù…Ø±Ù…Ù‰","ÙŠØ³Ø¬Ù„","Ø§Ù„Ø£ÙˆÙ„" ,"Ø§Ù„Ø«Ø§Ù†ÙŠ"," Ø§Ù„Ø«Ø§Ù„Ø«","Ø§Ù„Ø±Ø§Ø¨Ø¹","Ø§Ù„Ø®Ø§Ù…Ø³","ÙØ¹Ù„Ù‡Ø§","Ù‡Ø¯ÙØ§Ù†","ÙŠØ³Ø¯Ø¯","ÙŠØ³Ø¬Ù„","Ù‚ÙˆÙ„","Ø§Ù„ØªØ¹Ø§Ø¯Ù„","ØªØ¯Ø®Ù„","Ø§Ù„Ø±Ø¦Ø³ÙŠØ©","ØºÙˆÙ„","ÙˆØªØ³Ø¯ÙŠØ¯Ù‡","ÙŠØ­Ø·","Ø§Ù„ØªØ¹Ø§Ø¯Ù„","Ù…Ø´ Ù…Ù…ÙƒÙ†"," Ù„Ù…Ù† Ø§Ù„Ø­Ù„","Ø¬ÙˆÙ„"],
        "chance": ["Ø®Ø·ÙŠØ±Ø©", "Ù‡Ø¬ÙˆÙ…ÙŠØ©", "Ù…Ø±ØªØ¯Ø©", "Ø§Ù†ÙØ±Ø§Ø¯", "Ù…Ù…ÙƒÙ†Ø©","Ù…Ø¨Ø§Ø´Ø±Ø©","Ø¹Ø±Ø¶ÙŠØ©","Ø±ÙƒÙ†ÙŠØ©"],
        "save": ["ØªØµØ¯Ù‰", "Ø£Ù†Ù‚Ø°Ù‡Ø§", "Ø¥Ø¨Ø¹Ø§Ø¯", "ØµØ¯Ù‡Ø§", "Ù…Ù†Ø¹","Ø§Ø¶Ø§Ø¹Ù‡Ø§","ÙŠØ¶ÙŠØ¹Ù‡Ø§","Ø¶Ø§Ø¹Øª"],
        "card": ["Ø¨Ø·Ø§Ù‚Ø© Ø­Ù…Ø±Ø§Ø¡", "Ø¨Ø·Ø§Ù‚Ø© ØµÙØ±Ø§Ø¡", "Ø¥Ù†Ø°Ø§Ø±", "ØªØ¯Ø®Ù„ Ø¹Ù†ÙŠÙ", "Ø·Ø±Ø¯ Ù…Ø¨Ø§Ø´Ø±","ÙƒØ±Øª Ø§ØµÙØ±", "ÙƒØ±Øª Ø§Ø­Ù…Ø±"],
        "penalty": ["Ø¬Ø²Ø§Ø¡", "Ø¨Ù„Ù†ØªÙŠ", "Ø¬Ø²Ø§Ø¡","ÙŠØ³Ø¯Ø¯","ÙŠØ³Ø¬Ù„"],
        "shot": ["Ø£Ù„Ø§Ù‡ÙŠ","Ø§Ù„Ù„Ù‡","Ø§Ù„Ù„Ù‡","Ù‚ÙˆÙŠØ©", "ØµØ§Ø±ÙˆØ®", "Ù‚Ø°ÙŠÙØ©","Ø³Ù‡Ù„Ø©"," Ø¬Ù…ÙŠÙ„Ø©","Ø±ÙŠÙ…ÙˆÙ†ØªØ§Ø¯Ø©","ØªØ³Ù„Ù„"],
        "excitement": ["Ù…Ø¬Ù†ÙˆÙ†Ø©", "Ø®Ø·ÙŠØ±Ø©","Ø¶ØºØ·"]
        }
        self.reference_embeddings = self._embed_reference_phrases()

    def _clean_text(self, text):
        text = re.sub(r'(.)\1{2,}', r'\1', text)
        text = re.sub(r'[^\w\s]', '', text)
        return text.strip().lower()

    def _embed_reference_phrases(self):
        print("ğŸ” Ø­Ø³Ø§Ø¨ ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©...")
        embeddings = {}
        for label, phrases in self.reference_phrases.items():
            embeddings[label] = self.model.encode(phrases, convert_to_tensor=True)
        return embeddings

    def load_transcription(self, file_path):
        with open(file_path, encoding="utf-8") as f:
            return json.load(f)

    def generate_segments(self, words):
        segments = []
        for i in range(len(words) - self.window_size + 1):
            segment_text = " ".join([self._clean_text(words[j]['word']) for j in range(i, i + self.window_size)])
            segments.append({
                "text": segment_text,
                "start": words[i]['start'],
                "end": words[i + self.window_size - 1]['end']
            })
        return segments

    def classify_segments(self, segments):
        important_moments = []
        for seg in tqdm(segments, desc="ğŸ§  ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬Ù…Ù„"):
            seg_embedding = self.model.encode(seg['text'], convert_to_tensor=True)
            best_label = None
            best_score = 0.0

            for label, refs in self.reference_embeddings.items():
                score = util.pytorch_cos_sim(seg_embedding, refs).max().item()
                if score > self.threshold and score > best_score:
                    best_label = label
                    best_score = score

            if best_label:
                important_moments.append({
                    "label": best_label,
                    "text": seg['text'],
                    "start": seg['start'],
                    "end": seg['end'],
                    "score": round(best_score, 2)
                })

        return important_moments

    def save_results(self, results, output_file="important_moments.json"):
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù„Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ: {output_file}")

    def process(self, transcription_path, output_path="important_moments.json"):
        print("ğŸ“‚ ØªØ­Ù…ÙŠÙ„ ØªÙØ±ÙŠØº Whisper...")
        words = self.load_transcription(transcription_path)
        print("ğŸ“„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø§Ø·Ø¹ Ù‚ØµÙŠØ±Ø©...")
        segments = self.generate_segments(words)
        print("ğŸ” ØªØµÙ†ÙŠÙ Ø§Ù„Ù„Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©...")
        moments = self.classify_segments(segments)
        self.save_results(moments, output_path)
        return moments
