import os
import subprocess
import whisper
import json
from tqdm import tqdm
import torch

class WhisperTranscriber:
    def __init__(self, model_size="medium"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸš€ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¬Ù‡Ø§Ø²: {self.device.upper()}")
        print(f"ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper Ø¨Ø§Ù„Ø­Ø¬Ù…: {model_size}")
        self.model = whisper.load_model(model_size).to(self.device)

    def extract_audio_with_ffmpeg(self, video_path, output_audio_path="temp_audio.wav"):
        print("ğŸï¸ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...")
        command = [
            "ffmpeg", "-y",
            "-i", video_path,
            "-ac", "1",         # Ù‚Ù†Ø§Ø© ØµÙˆØªÙŠØ© ÙˆØ§Ø­Ø¯Ø©
            "-ar", "16000",     # 16 kHz
            "-vn",              # Ø¨Ø¯ÙˆÙ† ÙÙŠØ¯ÙŠÙˆ
            output_audio_path
        ]
        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return output_audio_path

    def transcribe_audio_to_json(self, audio_path, json_path="transcription.json"):
        print("ğŸ§  Ø¨Ø¯Ø¡ Ø§Ù„ØªÙØ±ÙŠØº Ø§Ù„ØµÙˆØªÙŠ...")
        result = self.model.transcribe(
            audio_path,
            word_timestamps=True,
            verbose=False,
            fp16=(self.device == "cuda")
        )

        words_data = []
        for segment in tqdm(result["segments"], desc="ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª"):
            for word_info in segment.get("words", []):
                words_data.append({
                    "word": word_info["word"].strip(),
                    "start": round(word_info["start"], 2),
                    "end": round(word_info["end"], 2)
                })

        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(words_data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ {json_path}")
        return result["text"]

    def transcribe_video(self, video_path, json_path="transcription.json"):
        audio_path = self.extract_audio_with_ffmpeg(video_path)
        full_text = self.transcribe_audio_to_json(audio_path, json_path)
        os.remove(audio_path)
        print("\nğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„:")
        print(full_text)
        return full_text

# ğŸ§ª Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    video_file = "inpute/xall.mp4"  # ØºÙŠÙ‘Ø± Ø­Ø³Ø¨ Ù…Ø³Ø§Ø± Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
    transcriber = WhisperTranscriber(model_size="medium")
    text = transcriber.transcribe_video(video_file)
